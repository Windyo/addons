---
version: latest
slug: whisper-cuda
name: Whisper-Cuda
description: Speech-to-text with Whisper using GPU 
url: https://github.com/windyo/addons/blob/master/
devices:
  - /dev/fb0
arch:
  - amd64
init: false
discovery:
  - wyoming
backup_exclude:
  - "models*"
map:
  - addon_config:rw
options:
  model: auto
  language: en
  beam_size: 0
  custom_model_type: "faster-whisper"
  debug_logging: false
schema:
  model: |
    list(auto|tiny-int8|tiny|tiny.en|base-int8|base|base.en|small-int8|distil-small.en|small|small.en|distil-medium.en|medium-int8|medium|medium.en|large|large-v1|distil-large-v2|large-v2|distil-large-v3|large-v3|turbo|custom)
  custom_model: str?
  custom_model_type: |
    list(faster-whisper)
  language: |
    list(auto|af|am|ar|as|az|ba|be|bg|bn|bo|br|bs|ca|cs|cy|da|de|el|en|es|et|eu|fa|fi|fo|fr|gl|gu|ha|haw|he|hi|hr|ht|hu|hy|id|is|it|ja|jw|ka|kk|km|kn|ko|la|lb|ln|lo|lt|lv|mg|mi|mk|ml|mn|mr|ms|mt|my|ne|nl|nn|no|oc|pa|pl|ps|pt|ro|ru|sa|sd|si|sk|sl|sn|so|sq|sr|su|sv|sw|ta|te|tg|th|tk|tl|tr|tt|uk|ur|uz|vi|yi|yo|zh|yue)
  beam_size: int
  initial_prompt: str?
  debug_logging: bool
  device: list(cpu|cuda)
ports:
  "10300/tcp": null
homeassistant: 2023.8.0.dev20230728
  #image: registry.docker.com/windyo/faster-whisper-cuda
